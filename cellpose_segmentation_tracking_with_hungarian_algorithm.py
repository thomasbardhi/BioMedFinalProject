# -*- coding: utf-8 -*-
"""Cellpose Segmentation_Tracking With Hungarian Algorithm.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FBur9-AD1BpBylIVK-wHuPJtTlwVTG1E
"""

# Commented out IPython magic to ensure Python compatibility.
try:
  from google.colab import drive
  IN_COLAB=True
except:
  IN_COLAB=False

if IN_COLAB:
  print("We're running Colab")
  
if IN_COLAB:
  # Mount the Google Drive at mount
  mount='/content/gdrive'
  print("Colab: mounting Google drive on ", mount)

  drive.mount(mount)

  # Switch to the directory on the Google Drive that you want to use
  import os
  drive_root = mount + "/My Drive/Colab Notebooks/Biomedical Image Analysis/Final Project"
  
  # Create drive_root if it doesn't exist
  create_drive_root = True
  if create_drive_root:
    print("\nColab: making sure ", drive_root, " exists.")
    os.makedirs(drive_root, exist_ok=True)
  
  # Change to the directory
  print("\nColab: Changing directory to ", drive_root)
#   %cd $drive_root

!pip install cellpose 
!pip install mxnet-cu102

import os
import tifffile as tiff
import numpy as np
import cv2
from skimage import exposure
import matplotlib.pyplot as plt
import scipy.ndimage as ndi

from scipy.optimize import linear_sum_assignment
from scipy.spatial.distance import cdist
from cellpose import models
from tifffile import imread, imwrite

#saves the mask of the images and cellpose prediction and also calculates the centroids of each mask
#stores it in a list that we can implement in tracking
def process_images(image_files, output_dir):
    # Initialize Cellpose model
    # model_type='nuclei' for nuclear segmentation
    model = models.Cellpose(gpu=True, model_type='nuclei')
    centriods_each_image = []
    # Iterate over all image files in the provided list
    for image_path in image_files:
        # Read the image
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        image = image

        # Normalize image to 0-1
        image = (image - np.min(image)) / (np.max(image) - np.min(image))
        image = image.astype(np.float32)

        # Run the model on the image
        masks, flows, styles, diams = model.eval(image, diameter=None, channels=[0,0])

        # Scale masks for visualization
        masks_scaled = (masks / np.max(masks) * 255).astype(np.uint8)

        # Generate filename from the image path
        filename = os.path.basename(image_path)

        # Save the results as a .tif image
        output_path = os.path.join(output_dir, f"watershed_{os.path.splitext(filename)[0]}.tif")
        imwrite(output_path, flows[0])
        output_path = os.path.join(output_dir, f"mask_{os.path.splitext(filename)[0]}.tif")
        imwrite(output_path, masks_scaled)
        
        #calculate the centriods of the masks
        #this will be used in tracking
        # Identify the unique cells in the mask
        cell_ids = np.unique(masks)[1:]  # Exclude 0 (background)

        # Calculate the centroid of each cell
        centroids = np.array([ndi.center_of_mass(masks == cell_id) for cell_id in cell_ids])
        centriods_each_image.append(centroids)
    return centriods_each_image
        

# Specify the input and output directories
image_dir = '/content/gdrive/MyDrive/Colab Notebooks/Biomedical Image Analysis/Final Project/Images_Test'
output_dir = '/content/gdrive/MyDrive/Colab Notebooks/Biomedical Image Analysis/Final Project/SegImg_Test'

# Generate a sorted list of image file paths
image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.tif')]
image_files.sort()

# Process the images
cent_pts = process_images(image_files[0:50], output_dir)



from scipy.optimize import linear_sum_assignment
from scipy.spatial.distance import cdist
import matplotlib.pyplot as plt

# Let's assume you have a list of centroid sets for each frame
all_centroids = cent_pts 

# Initialize an empty list to hold the tracking results
tracks = []

# Loop over each pair of consecutive frames
for i in range(len(all_centroids) - 1):
    centroids_frame1 = all_centroids[i][:, [1, 0]]
    centroids_frame2 = all_centroids[i + 1][:, [1, 0]]

    # Calculate cost matrix (Euclidean distance between each pair of points)
    cost_matrix = cdist(centroids_frame1, centroids_frame2)

    # Use the Hungarian method to find the optimal assignment
    row_ind, col_ind = linear_sum_assignment(cost_matrix)

    # Store the results in the tracks list
    tracks.append((row_ind, col_ind))

# Now, to visualize the results:
for i in range(len(tracks)):
    row_ind, col_ind = tracks[i]
    centroids_frame1 = all_centroids[i]
    centroids_frame2 = all_centroids[i + 1]

    # Plot the centroids for this frame
    plt.scatter(centroids_frame1[row_ind, 0], centroids_frame1[row_ind, 1], c='r')
    plt.scatter(centroids_frame2[col_ind, 0], centroids_frame2[col_ind, 1], c='b')

    # Draw lines between matched centroids
    for r, c in zip(row_ind, col_ind):
        plt.plot([centroids_frame1[r, 0], centroids_frame2[c, 0]],
                 [centroids_frame1[r, 1], centroids_frame2[c, 1]], 'k-')

plt.show()

images = []
for image_path in image_files[0:0]: #changed from 100 to 50 to match centroid length
    image = cv2.imread(image_path)
    if image is not None:
        images.append(image)

all_images = images  # We already limited the image_files to 10
all_centroids = cent_pts  # Replace with your list of centroid sets

# Ensure that all_images and all_centroids have the same length
assert len(all_images) == len(all_centroids)

# Create a VideoWriter object
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
video = cv2.VideoWriter('tracked_cells.mp4', fourcc, 30.0, (all_images[0].shape[1], all_images[0].shape[0]), isColor=True)

# Initialize an empty list to hold the tracking results
tracks = []

# Loop over each pair of consecutive frames
for i in range(len(all_centroids) - 1):
    centroids_frame1 = all_centroids[i]
    centroids_frame2 = all_centroids[i + 1]

    # Calculate cost matrix (Euclidean distance between each pair of points)
    cost_matrix = cdist(centroids_frame1, centroids_frame2)

    # Use the Hungarian method to find the optimal assignment
    row_ind, col_ind = linear_sum_assignment(cost_matrix)

    # Store the results in the tracks list
    tracks.append((row_ind, col_ind))

# Now, to visualize the results:
for i in range(len(tracks)):
    row_ind, col_ind = tracks[i]
    centroids_frame1 = all_centroids[i][:, [1, 0]]
    centroids_frame2 = all_centroids[i + 1][:, [1, 0]]

    # Create a copy of the image for this frame
    img = all_images[i].copy()

    # Draw the centroids for this frame
    for r in row_ind:
        cv2.circle(img, tuple(centroids_frame1[r].astype(int)), 5, (0, 0, 255), -1)  # Red circles

    for c in col_ind:
        cv2.circle(img, tuple(centroids_frame2[c].astype(int)), 5, (255, 0, 0), -1)  # Blue circles

    # Draw lines between matched centroids
    for r, c in zip(row_ind, col_ind):
        cv2.line(img, tuple(centroids_frame1[r].astype(int)), tuple(centroids_frame2[c].astype(int)), (0, 255, 0), 2)  # Green lines

    # Add the frame to the video
    video.write(img)

# Release the VideoWriter
video.release()

from IPython.display import HTML
from base64 import b64encode

# Open the video file in binary mode
with open('tracked_cells.mp4', 'rb') as f:
    video_file = f.read()

# Convert the video file to base64
video_url = "data:video/mp4;base64," + b64encode(video_file).decode()

# Display the video
HTML(f"""
<video width=400 controls>
      <source src="{video_url}" type="video/mp4">
</video>
""")

!ffprobe -show_entries stream=r_frame_rate,nb_read_frames,duration -select_streams v -count_frames -of compact=p=1:nk=1 -threads 3 -v 0 tracked_cells.mp4

image = images[0]  # Replace with your image
centroids = cent_pts[0]  # Replace with your centroids

plt.figure(figsize=(10, 10))
plt.imshow(image)

# Swap x and y coordinates of the centroids
swapped_centroids = centroids[:, [1, 0]]

plt.scatter(swapped_centroids[:, 0], swapped_centroids[:, 1], c='r', marker='o', s=50)
plt.title(f"Image with Centroids")
plt.axis('off')
plt.show()



