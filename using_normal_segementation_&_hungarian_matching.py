# -*- coding: utf-8 -*-
"""Using Normal Segementation & Hungarian Matching

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MwNWqmt57WxCtO9F2nYVg2nLQho2kR9p
"""

# Commented out IPython magic to ensure Python compatibility.
try:
  from google.colab import drive
  IN_COLAB=True
except:
  IN_COLAB=False

if IN_COLAB:
  print("We're running Colab")
  
if IN_COLAB:
  # Mount the Google Drive at mount
  mount='/content/gdrive'
  print("Colab: mounting Google drive on ", mount)

  drive.mount(mount)

  # Switch to the directory on the Google Drive that you want to use
  import os
  drive_root = mount + "/My Drive/Colab Notebooks/Biomedical Image Analysis/Final Project"
  
  # Create drive_root if it doesn't exist
  create_drive_root = True
  if create_drive_root:
    print("\nColab: making sure ", drive_root, " exists.")
    os.makedirs(drive_root, exist_ok=True)
  
  # Change to the directory
  print("\nColab: Changing directory to ", drive_root)
#   %cd $drive_root

# Commented out IPython magic to ensure Python compatibility.
#code borrow and modified from https://github.com/Connor323/Cancer-Cell-Tracking/blob/master/Code/Celltracker.ipynb
# %matplotlib inline

import os
import cv2
import PIL.Image
import sys
import numpy as np
from IPython.display import Image, display, clear_output
import matplotlib.pyplot as plt
import scipy

def normalize(image):
    cv2.normalize(image, image, 0, 255, cv2.NORM_MINMAX)
    return image

# read image sequence
path = '/content/gdrive/MyDrive/Colab Notebooks/Biomedical Image Analysis/Final Project/Images_Test'
for r,d,f in os.walk(path):
    images = []
    enhance_images = []
    f = sorted(f)
    for files in f:
        if files[-3:].lower()=='tif':
            temp = cv2.imread(os.path.join(r,files))
            gray = cv2.cvtColor(temp, cv2.COLOR_BGR2GRAY) 
            images.append(gray.copy())
            enhance_images.append(normalize(gray.copy()))

print("Total number of image is ", len(images))
print("The shape of image is ", images[0].shape, type(images[0][0,0]))

# Helper functions
def display_image(img):
    assert img.ndim == 2 or img.ndim == 3
    h, w = img.shape[:2]
    if len(img.shape) == 3:
        img = cv2.resize(img, (w/3, h/3, 3))
    else:
        img = cv2.resize(img, (w/3, h/3))
    cv2.imwrite("temp_img.png", img)
    img = Image("temp_img.png")
    display(img)

def vis_square(data, title=None):
    """
    Take an array of shape (n, height, width) or (n, height, width, 3)
    and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)
    """
    # resize image into small size
    _, h, w = data.shape[:3] 
    width = int(np.ceil(1200. / np.sqrt(data.shape[0])))    # the width of showing image 
    height = int(np.ceil(h*float(width)/float(w))) # the height of showing image 
    if len(data.shape) == 4:
        temp = np.zeros((data.shape[0], height, width, 3))
    else:
        temp = np.zeros((data.shape[0], height, width))
    
    for i in range(data.shape[0]):
        if len(data.shape) == 4:
            temp[i] = cv2.resize(data[i], (width, height, 3))
        else:
            temp[i] = cv2.resize(data[i], (width, height))
    
    data = temp
    
    # force the number of filters to be square
    n = int(np.ceil(np.sqrt(data.shape[0])))
    padding = (((0, n ** 2 - data.shape[0]),
              (0, 2), (0, 2))                 # add some space between filters
              + ((0, 0),) * (data.ndim - 3))  # don't pad the last dimension (if there is one)
    data = np.pad(data, padding, mode='constant', constant_values=255)  # pad with ones (white)
    
    # tile the filters into an image
    data = data.reshape((n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))
    data = data.reshape((n * data.shape[1], n * data.shape[3]) + data.shape[4:])
    
    # show image
    cv2.imwrite("temp_img.png", data)
    img = Image("temp_img.png")
    display(img)

def cvt_npimg(images):
    """
    Convert image sequence to numpy array
    """
    h, w = images[0].shape[:2]
    if len(images[0].shape) == 3:
        out = np.zeros((len(images), h, w, 3))
    else:
        out = np.zeros((len(images), h, w))
    for i, img in enumerate(images):
        out[i] = img
    return out

#Write image from different input
def write_mask16(images, name, index=-1):
    """
    Write image as 16 bits image
    """
    if index == -1:
        for i, img in enumerate(images):
            if i < 10:
                cv2.imwrite(name+"00"+str(i)+".tif", img.astype(np.uint16))
            elif i >= 10 and i < 100:
                cv2.imwrite(name+"0"+str(i)+".tif", img.astype(np.uint16))
            else:
                cv2.imwrite(name+str(i)+".tif", img.astype(np.uint16))
    else:
        if index < 10:
            cv2.imwrite(name+"00"+str(index)+".tif", images.astype(np.uint16))
        elif index >= 10 and index < 100:
            cv2.imwrite(name+"0"+str(index)+".tif", images.astype(np.uint16))
        else:
            cv2.imwrite(name+str(index)+".tif", images.astype(np.uint16))   

def write_mask8(images, name, index=-1):
    """
    Write image as 8 bits image
    """
    if index == -1:
        for i, img in enumerate(images):
            if i < 10:
                cv2.imwrite(name+"00"+str(i)+".tif", img.astype(np.uint8))
            elif i >= 10 and i < 100:
                cv2.imwrite(name+"0"+str(i)+".tif", img.astype(np.uint8))
            else:
                cv2.imwrite(name+str(i)+".tif", img.astype(np.uint8))
    else:
        if index < 10:
            cv2.imwrite(name+"000"+str(index)+".tif", images.astype(np.uint8))
        elif index >= 10 and index < 100:
            cv2.imwrite(name+"00"+str(index)+".tif", images.astype(np.uint8))
        elif index >= 100 and index < 1000:
            cv2.imwrite(name+"0"+str(index)+".tif", images.astype(np.uint8)) 
        elif index >= 1000 and index < 10000:
            cv2.imwrite(name+str(index)+".tif", images.astype(np.uint8)) 
        else:
            raise

def write_pair8(images, name, index=-1):
    """
    Write image as 8 bits image with dilation
    """
    for i, img in enumerate(images):    
        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))
        img = cv2.dilate((img*255).astype(np.uint8),kernel,iterations = 3)
        if i < 10:
            cv2.imwrite(name+"00"+str(i)+".tif", img)
        elif i >= 10 and i < 100:
            cv2.imwrite(name+"0"+str(i)+".tif", img)
        else:
            cv2.imwrite(name+str(i)+".tif", img)

#CELL SEGMENTATION
th = None
img = None

class ADPTIVETHRESH():
    '''
    This class is to provide all function for adaptive thresholding.

    '''
    def __init__(self, images):
        self.images = []
        for img in images:
            if len(img.shape) == 3:
                img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            self.images.append(img.copy())

    def applythresh(self, threshold = 50):
        '''
        applythresh function is to convert original image to binary image by thresholding.

        Input: image sequence. E.g. [image0, image1, ...]

        Output: image sequence after thresholding. E.g. [image0, image1, ...]
        '''
        out = []
        markers = []
        binarymark = []

        for img in self.images:
            img = cv2.GaussianBlur(img,(5,5),0).astype(np.uint8)
            _, thresh = cv2.threshold(img,threshold,1,cv2.THRESH_BINARY)

            # Using morphlogical operations to imporve the quality of result
            kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(9,9))
            thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)

            out.append(thresh)

        return out

global th
global img

adaptive = ADPTIVETHRESH(enhance_images)
th = adaptive.applythresh(50)

for i,img in enumerate(th):
    th[i] = img*255
os.chdir(".")
write_mask8(th, "thresh")
out = cvt_npimg(th)
vis_square(out)

looplimit = 500

newimg = None
pair = None

def inbounds(shape, indices):
    assert len(shape) == len(indices)
    for i, ind in enumerate(indices):
        if ind < 0 or ind >= shape[i]:
            return False
    return True

class GVF():
    '''
    This class contains all function for calculating GVF and its following steps.
    
    '''
    def __init__(self, images, thresh):
        
        self.images = images
        self.thresh = thresh

    def distancemap(self):
        '''
        This function is to generate distance map of the thresh image. We use the opencv
        function distanceTransform to generate it. Moreover, in this case, we use Euclidiean
        Distance (DIST_L2) as a metric of distance. 

        Input: None

        Output: Image distance map

        '''
        return [cv2.distanceTransform(self.thresh[i], distanceType=2, maskSize=0)\
                for i in range(len(self.thresh))]

    def new_image(self, alpha, dismap):
        '''
        This function is to generate a new image combining the oringal image I0 with
        the distance map image Idis by following expression:
                                Inew = I0 + alpha*Idis
        In this program, we choose alpha as 0.4.

        Input: the weight of distance map: alpha
               the distance map image

        Output: new grayscale image

        '''

        return [self.images[i] + alpha * dismap[i] for i in range(len(self.thresh))]

    def compute_gvf(self, newimage):
        '''
        This function is to compute the gradient vector of the imput image.

        Input: a grayscale image with size, say m * n * # of images

        Output: a 3 dimentional image with size, m * n * 2, where the last dimention is
        the gradient vector (gx, gy)

        '''
        kernel_size = 5 # kernel size for blur image before compute gradient
        newimage = [cv2.GaussianBlur((np.clip(newimage[i], 0, 255)).astype(np.uint8),(kernel_size,kernel_size),0)\
                    for i in range(len(self.thresh))]
        # use sobel operator to compute gradient 
        temp = np.zeros((newimage[0].shape[0], newimage[0].shape[1], 2), np.float32) # store temp gradient image 
        gradimg = []  # output gradient images (height * weight * # of images)

        for i in range(len(newimage)):
            # compute sobel operation in x, y directions
            gradx = cv2.Sobel(newimage[i],cv2.CV_64F,1,0,ksize=3)
            grady = cv2.Sobel(newimage[i],cv2.CV_64F,0,1,ksize=3)
            # add the gradient vector
            temp[:,:,0], temp[:,:,1] = gradx, grady
            gradimg.append(temp)

        return gradimg

    def find_certer(self, gvfimage, index):
        '''
        This function is to find the center of Nuclei.

        Input: the gradient vector image (height * weight * 2).

        Output: the record image height * weight).

        '''
        # Initialize a image to record seed candidates.
        imgpair = np.zeros(gvfimage.shape[:2])

        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))
        dilate = cv2.dilate(self.thresh[index].copy(), kernel, iterations = 1)
        erthresh = cv2.erode(dilate, kernel, iterations = 3)
        while erthresh.sum() > 0:

            print("Image ", index, "left: ", erthresh.sum(), "points")
            # Initialize partical coordinates [y, x]
            y0, x0 = np.where(erthresh>0)
            p0 = np.array([y0[0], x0[0], 1])

            # Initialize record coordicates [y, x]
            p1 = np.array([5000, 5000, 1])

            # mark the first non-zero point of thresh image to 0
            erthresh[p0[0], p0[1]] = 0

            # a variable to record if the point out of bound of image or 
            # out of maximum loop times
            outbound = False

            # count loop times to limit max loop times
            count = 0

            while sp.distance.cdist([p0],[p1]) > 1:

                count += 1
                p1 = p0
                u = gvfimage[p0[0], p0[1], 1]
                v = gvfimage[p0[0], p0[1], 0]
                M = np.array([[1, 0, u],\
                              [0, 1, v],\
                              [0, 0, 1]], np.float32)
                p0 = M.dot(p0)
                if not inbounds(self.thresh[index].shape, (p0[0], p0[1])) or count > looplimit:
                    outbound = True
                    break

            if not outbound:
                imgpair[p0[0], p0[1]] += 1
            clear_output(wait=True)

        return imgpair.copy()

from scipy import spatial as sp
from scipy import ndimage
from scipy.spatial import distance

gvf = GVF(images, th)
dismap = gvf.distancemap()
newimg = gvf.new_image(0.4, dismap) # choose alpha as 0.4.
out = []
pair = []
kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(5,5))
for i,img in enumerate(dismap):
    neighborhood_size = 20
    data_max = ndimage.filters.maximum_filter(img, neighborhood_size)
    data_max[data_max==0] = 255
    pair.append((img == data_max).astype(np.uint8))
    y, x = np.where(pair[i]>0)
    points = zip(y[:], x[:])
    points = list(zip(y[:], x[:]))
    dmap = distance.cdist(points, points, 'euclidean')
    y, x = np.where(dmap<20)
    ps = zip(y[:], x[:])
    for p in ps:
        if p[0] != p[1]:
            pair[i][points[min(p[0], p[1])]] = 0
    dilation = cv2.dilate((pair[i]*255).astype(np.uint8),kernel,iterations = 1)
    out.append(dilation)
    os.chdir(".")
    write_mask8(dilation, "seed_point", i)

out = cvt_npimg(out)
vis_square(out)

import cv2
import numpy as np
from numpy import unique
import copy as cp

bmarks = None
marks = None

class WATERSHED():
    '''
    This class contains all the function to compute watershed.

    '''
    def __init__(self, images, markers):
        self.images = images
        self.markers = markers

    def is_over_long(self, img, max_lenth=50):
        rows = np.any(img, axis=1)
        cols = np.any(img, axis=0)
        if not len(img[img>0]):
            return True
        rmin, rmax = np.where(rows)[0][[0, -1]]
        cmin, cmax = np.where(cols)[0][[0, -1]]
        if (rmax-rmin)>max_lenth or (cmax-cmin)>max_lenth:
            return True
        else:
            return False
    
    def watershed_compute(self):
        '''
        This function is to compute watershed given the newimage and the seed image
        (center candidates). In this function, we use cv2.watershed to implement watershed.

        Input: newimage (height * weight * # of images)

        Output: watershed images (height * weight * # of images)

        '''
        result = []
        outmark = []
        outbinary = []

        for i in range(len(self.images)):
            print("image: ", i)
            # generate a 3-channel image in order to use cv2.watershed
            imgcolor = np.zeros((self.images[i].shape[0], self.images[i].shape[1], 3), np.uint8)
            for c in range(3): 
                imgcolor[:,:,c] = self.images[i]

            # compute marker image (labelling)
            if len(self.markers[i].shape) == 3:
                self.markers[i] = cv2.cvtColor(self.markers[i],cv2.COLOR_BGR2GRAY)
            _, mark = cv2.connectedComponents(self.markers[i])
            
            # watershed!
            mark = cv2.watershed(imgcolor,mark)
            
            u, counts = unique(mark, return_counts=True)
            counter = dict(zip(u, counts))
            for index in counter:
                temp_img = np.zeros_like(mark)
                temp_img[mark==index] = 255
                if self.is_over_long(temp_img):
                    mark[mark==index] = 0
                    continue
                if counter[index] > 3000:
                    mark[mark==index] = 0
                    continue
            
            labels = list(set(mark[mark>0]))
            length = len(labels)
            temp_img = mark.copy()
            for original, new in zip(labels, range(1,length+1)):
                temp_img[mark==original] = new
            mark = temp_img
                
            # mark image and add to the result 
            temp = cv2.cvtColor(imgcolor,cv2.COLOR_BGR2GRAY)
            result.append(temp)
            outmark.append(mark.astype(np.uint8))

            binary = mark.copy()
            binary[mark>0] = 255
            outbinary.append(binary.astype(np.uint8))
            clear_output(wait=True)

        return result, outbinary, outmark

#import the mathmatically segemented data
from skimage.measure import label, regionprops
from skimage.io import imread
image_dir = '/content/gdrive/MyDrive/Colab Notebooks/Biomedical Image Analysis/Final Project/seedseg'

image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.tif')]
image_files.sort()

all_centroids = []

for image_path in image_files:
        # Read the image
        image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
        image = image

        # Normalize image to 0-1
        image = (image - np.min(image)) / (np.max(image) - np.min(image))
        image = image.astype(np.float32)
        
        #calculate the centriods of the masks
        #this will be used in tracking
        # Identify the unique cells in the mask

        # Calculate the centroid of each cell

        # Label the image (each segment gets a unique integer)
        labelled_image = label(img)

    # Get properties of each region
        props = regionprops(labelled_image)

    # List to hold centroids for this image
        centroids = []

    # Get the centroid of each region
        for prop in props:
          centroids.append(prop.centroid)

    # Swap coordinates (x, y) to (y, x), and convert to a numpy array

    # Add these centroids to the list of all centroids
        all_centroids.append(centroids)

from scipy.optimize import linear_sum_assignment
from scipy.spatial.distance import cdist
from tifffile import imread, imwrite

images = []
image_dir = '/content/gdrive/MyDrive/Colab Notebooks/Biomedical Image Analysis/Final Project/Images_Test'


# Generate a sorted list of image file paths
image_f = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.tif')]
image_f.sort()
for image_path in image_f: 
    image = cv2.imread(image_path)
    if image is not None:
        images.append(image)

all_images = images  # We already limited the image_files to 10

# Ensure that all_images and all_centroids have the same length
assert len(all_images) == len(all_centroids)
print(len(all_images))
print(all_centriods)
# Create a VideoWriter object
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
video = cv2.VideoWriter('tracked_cells.mp4', fourcc, 30.0, (all_images[0].shape[1], all_images[0].shape[0]), isColor=True)

# Initialize an empty list to hold the tracking results
tracks = []

# Loop over each pair of consecutive frames
for i in range(len(all_centroids) - 1):
    centroids_frame1 = all_centroids[i]
    centroids_frame2 = all_centroids[i + 1]

    # Calculate cost matrix (Euclidean distance between each pair of points)
    cost_matrix = cdist(centroids_frame1, centroids_frame2)

    # Use the Hungarian method to find the optimal assignment
    row_ind, col_ind = linear_sum_assignment(cost_matrix)

    # Store the results in the tracks list
    tracks.append((row_ind, col_ind))

# Now, to visualize the results:
for i in range(len(tracks)):
    row_ind, col_ind = tracks[i]
    centroids_frame1 = all_centroids[i][:, [1, 0]]
    centroids_frame2 = all_centroids[i + 1][:, [1, 0]]

    # Create a copy of the image for this frame
    img = all_images[i].copy()

    # Draw the centroids for this frame
    for r in row_ind:
        cv2.circle(img, tuple(centroids_frame1[r].astype(int)), 5, (0, 0, 255), -1)  # Red circles

    for c in col_ind:
        cv2.circle(img, tuple(centroids_frame2[c].astype(int)), 5, (255, 0, 0), -1)  # Blue circles

    # Draw lines between matched centroids
    for r, c in zip(row_ind, col_ind):
        cv2.line(img, tuple(centroids_frame1[r].astype(int)), tuple(centroids_frame2[c].astype(int)), (0, 255, 0), 2)  # Green lines

    # Add the frame to the video
    video.write(img)

# Release the VideoWriter
video.release()

from IPython.display import HTML
from base64 import b64encode

# Open the video file in binary mode
with open('tracked_cells.mp4', 'rb') as f:
    video_file = f.read()

# Convert the video file to base64
video_url = "data:video/mp4;base64," + b64encode(video_file).decode()

# Display the video
HTML(f"""
<video width=400 controls>
      <source src="{video_url}" type="video/mp4">
</video>
""")



